{% include lib/mathjax.html %}
# Stochastic Scenario

ในการวิเคราะห์ทั้งหมดที่ผ่านมา เราสมมติว่า label ที่ถูกต้องของ input $x\in X$ ใด ๆ นั้นสามารถระบุได้ชัดเจนด้วย
concept $c:X\to Y$ และในการเรียนรู้จากตัวอย่างข้อมูล เราสมมติให้ตัวอย่างข้อมูล $(x,y)$ แต่ละตัวนั้น เราได้ $x$
มาจากการสุ่มด้วยการกระจาย $D$ บน input space $X$ และ label $y$ นั้นได้รับมาจาก $y=c(x)$
เราเรียกสถานการณ์นี้ว่าเป็นแบบจำลองปัญหาการเรียนรู้แบบ deterministic

ในทางปฏิบัตินั้น เรามักจะเจอสถานการณ์ที่ข้อมูลใน input $x$ นั้นไม่เพียงพอที่จะสามารถแยกแยะ label ที่ถูกต้องได้
ตัวอย่างเช่น หากเราต้องการทำนายเพศของคนจากความสูงและน้ำหนัก
จะเห็นว่ามีคู่ลำดับของความสูงและน้ำหนักจำนวนมากที่สามารถเป็นเพศใดก็ได้ ลักษณะปัญหาแบบนี้ทำให้เราไม่สามารถหาฟังก์ชันที่ทำนาย label
$y$ จาก input $x$ ได้ถูกต้องเสมอ โดยสำหรับ input $x$ แต่ละตัว จะต้องมีการกระจายของความน่าจะเป็นที่ label $y$
ที่ถูกต้องจะมีค่าต่าง ๆ

ในสถานการณ์เช่นนี้ เราจะมองว่า $D$ เป็นการกระจายที่นิยามบน $X\times Y$ และตัวอย่างข้อมูล $(x,y)$
แต่ละตัวจะถูกสุ่มมาจาก $D$ โดยตรง และสำหรับ hypothesis $h\in H$ ใด ๆ เราจะนิยามให้
error ของ $h$ เป็น

$$
R(h)=\Pr_{(x,y)\sim D}[h(x)\neq y]=\text{E}_{(x,y)\sim D}[1_{h(x)\neq y}]
$$

เนื่องจากเราไม่สามารถทำนาย label $y$ ที่ถูกต้องจาก input $x$ ได้เสมอ แสดงว่าจะต้องไม่มี concept $c$
ที่ $R(c)=0$ แน่นอน นั่นคือ สำหรับฟังก์ชัน $f:X\to Y$ ใด ๆ $R(f)>0$ เสมอ
เราจะนิยามให้ _Bayes error_ $R^*$ เป็นค่า error ที่น้อยที่สุดที่เป็นไปได้จากฟังก์ชัน $f:X\to Y$ ใด ๆ
นั่นคือ

$$
R^* = \inf_{f:X\to Y}R(f)
$$
