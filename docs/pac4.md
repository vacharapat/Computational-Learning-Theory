{% include lib/mathjax.html %}
# ปัญหาที่เรียนรู้ยาก
ในหัวข้อนี้ เราจะมาดูตัวอย่าง concept class ที่กว้างขึ้นกว่า boolean conjunction ในหัวข้อที่แล้วเล็กน้อย
ซึ่งสามารถพิสูจน์ได้ว่าการเรียนรู้ concept class ดังกล่าวนี้ไม่สามารถทำได้อย่างมีประสิทธิภาพ
นอกจากทุกปัญหาในคลาส NP สามารถหาคำตอบได้อย่างมีประสิทธิภาพด้วยความมั่นใจสูง โดยปัญหาที่เราสนใจในหัวข้อนี้คือปัญหาการเรียนรู้
disjunction ของ boolean conjunction จำนวน 3 กลุ่ม เราเรียกปัญหานี้ว่าปัญหาการเรียนรู้ 3-term DNF

## ปัญหาการเรียนรู้ 3-term DNF
เราสามารถนิยามปัญหานี้ได้เช่นเดียวกับปัญหาการเรียนรู้ boolean conjunction
โดยที่ concept class $C$ ของเราจะเปลี่ยนเป็นเซตของ disjunction ในรูป

$$
T_1\lor T_2\lor T_3
$$

เมื่อแต่ละ $T_i$ เป็น boolean conjunction บน literal ของตัวแประ $x_1,\dots,x_n$
สังเกตว่าเราสามารถนิยามขนาดของ representation ของ 3-term DNF $c\in C$ ได้ด้วยผลบวกของจำนวน
literal ที่ปรากฏในแต่ละ $T_i$ ซึ่งจะมีค่าไม่เกิน $6n$ (เนื่องจากแต่ละ $T_i$ มี literal ได้ไม่เกิน $2n$ ตัว)
ดังนั้นเราจึงได้ว่า $size(c)\leq 6n$ สำหรับทุก concept $c\in C$ นั่นหมายความว่าอัลกอริทึมการเรียนรู้ที่มีประสิทธิภาพ
จะต้องใช้เวลาทำงานเป็น polynomial บน $1/\epsilon, 1/\delta$ และ $n$

เพื่อที่จะแสดงว่าปัญหา 3-term DNF นี้เรียนรู้ได้ยาก เราจะมาทำความเข้าใจความรู้พื้นฐานเพิ่มเติมก่อนเล็กน้อย

## กลุ่มปัญหา RP
สำหรับปัญหาการตัดสินใจ (decision problem) $X$ ใด ๆ เราจะกล่าวว่า $X\in RP$ หรือ $X$ อยู่ในกลุ่มปัญหา RP
ถ้ามีอัลกอริทึมเชิงสุ่ม $A$ ที่ทำงานภายในเวลาที่เป็น polynomial บนขนาดของ input และ

- สำหรับ input $a$ ที่มีคำตอบที่ถูกต้องเป็น NO เราจะได้ว่า $A(a)$ จะให้คำตอบเป็น NO
- สำหรับ input $a$ ที่มีคำตอบที่ถูกต้องเป็น YES เราจะได้ว่า $A(a)$ จะให้คำตอบเป็น YES ด้วยความน่าจะเป็นไม่น้อยกว่า $1/2$

เนื่องจาก $A$ เป็นอัลกอริทึมเชิงสุ่ม จึงทำให้การทำงานของ $A$ บน input $a$ ตัวเดียวกันในแต่ละครั้งอาจได้ผลแตกต่างกัน
จากเงื่อนไขของ $A$ จะเห็นว่า เมื่อใดก็ตามที่เราเรียก $A$ ให้ทำงานบน input $a$ ตัวหนึ่งแล้วได้ผลเป็น YES
แสดงว่า input $a$ ตัวนั้นจะต้องมีคำตอบที่ถูกต้องเป็น YES อย่างแน่นอน ในขณะที่หากได้ผลเป็น NO
เราไม่สามารถสรุปอย่างชัดเจนได้ว่าคำตอบที่ถูกต้องเป็นเช่นไร

สังเกตว่าหากเรามีอัลกอริทึม $A$ ที่มีคุณสมบัติดังกล่าว สำหรับ input $a$ ที่มีคำตอบที่ถูกต้องเป็น YES
ถ้าเราเรียกให้ $A$ ทำงานบน $a$ ซ้ำกันเป็นจำนวน $n$ ครั้ง (โดยการทำงานในแต่ละครั้งเป็นอิสระจากกัน)
เราจะได้ว่าความน่าจะเป็นที่เราไม่พบคำตอบเป็น YES เลยแม้แต่ครั้งเดียวจะมีค่าไม่เกิน $1/2^n$
เราสามารถใช้แนวคิดนี้ในการปรับปรุงอัลกอริทึมให้มีความน่าจะเป็นที่จะตอบถูกต้องสูงตามต้องการได้

ในปัจจุบันเราทราบว่ากลุ่มปัญหา RP นั้นครอบคลุมปัญหาทั้งหมดในกลุ่ม P และเป็นสับเซตของกลุ่มปัญหา NP
แต่ไม่ทราบว่า RP$=$NP หรือไม่

## การลดรูปปัญหา
แนวคิดหลักในการแสดงว่าปัญหา 3-term DNF นั้นเรียนรู้ได้ยาก คือการแสดงให้เห็นว่ามีปัญหาในกลุ่ม NP-complete
บางปัญหาที่สามารถลดรูปมาเป็นปัญหาการเรียนรู้ 3-term DNF ได้ กล่าวคือ เราจะแสดงกระบวนการแปลง input $a$ ใด ๆ ของปัญหา NP-complete
นั้นให้กลายเป็นเซตของตัวอย่างข้อมูล $S_a$ สำหรับปัญหา 3-term DNF โดยที่ขนาดของ $S_a$ นั้นเป็น polynomial
บนขนาดของ $a$ และแสดงให้เห็นว่า ถ้าเรามีอัลกอริทึมการเรียนรู้ $L$ ที่สามารถเรียนรู้ปัญหา 3-term DNF
ตามกรอบการเรียนรู้แบบ PAC ได้ เราจะสามารถนำผลการเรียนรู้นั้นไปคำนวณต่อเพื่อหาคำตอบที่ถูกต้องของ input $a$
ในปัญหาตั้งต้นได้ ซึ่งจะนำไปสู่ข้อสรุปที่ว่ามีปัญหา NP-complete ที่สามารถหาคำตอบที่ถูกต้องด้วยความมั่นใจสูงได้อย่างมีประสิทธิภาพ
หรือแสดงว่า RP=NP นั่นเอง

## consistent hypothesis
หัวใจหลักของการลดรูปปัญหาของเราก็คือ เราจะทำการแปลง input $a$ ของปัญหาต้นทางมาเป็นเซตของตัวอย่างข้อมูล $S_a$
โดยมีเงื่อนไขว่า คำตอบที่ถูกต้องของ $a$ ในปัญหาตั้งต้นนั้นจะเป็น YES ก็ต่อเมื่อตัวอย่างข้อมูล $S_a$ ที่ได้มานั้นจะต้อง _สอดคล้อง_
(consistent) กับ concept $c$ อย่างน้อยหนึ่งตัวใน $C$ โดยเรานิยามความสอดคล้องดังนี้

ให้ $$S=\{(x_1,y_1),\dots,(x_m,y_m)\}$$ เป็นเซตของตัวอย่างข้อมูลโดย $x_i\in X$ และ $$y_i\in\{0,1\}$$
สำหรับค่า $i=1,\dots,m$ ให้ $c$ เป็น concept ใด ๆ บน input space $X$ เราจะกล่าวว่า $c$
สอดคล้องกับ $S$ ถ้า $c(a_i)=y_i$ สำหรับทุกค่า $i=1,\dots,m$

ถ้า concept class $C$ นั่นสามารถเรียนรู้ได้อย่างมีประสิทธิภาพ เราจะสามารถตรวจสอบได้ด้วยความมั่นใจสูงว่ามี concept $c\in C$
ที่สอดคล้องกับเซตของตัวอย่างข้อมูล $$S=\{(x_1,y_1),\dots,(x_m,y_m)\}$$ หรือไม่
โดยเรากำหนดการกระจายตัวให้มีความน่าจะเป็นที่ข้อมูล $(x_i,y_i)$ แต่ละคู่จะถูกเลือกมีค่าเป็น $1/m$ เท่ากันทั้งหมด
และกำหนดค่า error parameter $\epsilon = 1/2m$ จากนั้นเรียกอัลกอริทึมการเรียนรู้ให้ทำงาน
ด้วยวิธีการนี้ สังเกตว่าถ้าใน $C$ มี concept $c$ อย่างน้อยหนึ่งตัวที่สอดคล้องกับ $S$
อัลกอริทึมการเรียนรู้จะให้ผลเป็น $c\in C$ ที่สอดคล้องกับ $S$ ด้วยความน่าจะเป็นไม่ต่ำกว่า $1-\delta$
เนื่องจากถ้ามีตัวอย่างข้อมูลใน $S$ สักตัวที่ hypothesis $h$ ที่ได้จากการเรียนรู้ตอบผิด ค่า error
$R(h)$ จะมีค่าอย่างน้อย $1/m=2\epsilon>\epsilon$ ในทางกลับกัน หากใน $C$ ไม่มี concept ใดเลยที่สอดคล้องกับ $S$
อัลกอริทึมการเรียนรู้ของเราก็จะไม่สามารถหา concept ที่สอดคล้องมาได้แน่นอน จากตรงนี้จะเห็นว่า
หาก $C$ สามารถเรียนรู้ได้อย่างมีประสิทธิภาพ ปัญหาการตรวจสอบความสอดคล้องของเซต $S$ กับ $C$ นี้จะอยู่ในกลุ่มปัญหา RP
ดังนั้น หากเราสามารถลดรูปปัญหา NP-complete ให้กลายมาเป็นปัญหาการตรวจสอบความสอดคล้องเช่นนี้ได้
จากสมมติฐานที่ว่า RP$\neq$NP เราก็จะสรุปได้ว่าอัลกอริทึมการเรียนรู้ $C$ ที่มีประสิทธิภาพนั้นจะมีอยู่จริงไม่ได้

## การลดรูปจากปัญหาการระบายสามสีบนกราฟ
ถึงตรงนี้ สิ่งที่เหลือในการแสดงว่าปัญหาการเรียนรู้ 3-term DNF นั้นเป็นปัญหาที่ยาก ก็คือการแสดงให้เห็นว่ามีปัญหา
NP-complete ที่สามารถลดรูปมาเป็นปัญหาการตรวจสอบความสอดคล้องของ 3-term DNF ได้
ปัญหาที่เราจะใช้แสดงการลดรูปนี้ก็คือปัญหา _การระบายสามสีบนกราฟ_ หรือ Graph 3-Coloring ซึ่งมีนิยามดังนี้

**ปัญหาการระบายสามสีบนกราฟ**
ให้กราฟแบบไม่มีทิศทาง $G=(V,E)$ โดย $$V=\{1,\dots,n\}$$ และ $$E\subseteq V\times V$$
ต้องการตรวจสอบว่าเราสามารถระบายสีลงบนจุดยอดแต่ละจุดใน $V$ โดยใช้สีไม่เกิน 3 สีและให้เส้นเชื่อม $(i,j)\in E$
แต่ละเส้นมีสีที่จุดปลายทั้งสองด้านไม่เหมือนกันได้หรือไม่

เราจะแปลง input ของปัญหาจากกราฟ $G=(V,E)$ มาเป็นเซตของตัวอย่างข้อมูล $S_G$ ดังนี้
สำหรับแต่ละจุดยอด $i\in V$ เราจะสร้าง positive example $(a, 1)$ โดยที่ $a$ เป็น bit string
ความยาวเท่ากับ $n$ ที่มีบิตที่ $i$ เป็น 0 และบิตอื่น ๆ เป็น 1 ทั้งหมด
นอกจากนี้ สำหรับเส้นเชื่อม $(i,j)\in E$ แต่ละเส้น เราจะสร้าง negative example
$(a, 0)$ โดย $a$ มีบิตที่ $i$ และ $j$ เป็น 0 และบิตอื่น ๆ เป็น 1 ทั้งหมด
ตัวอย่างเช่น กราฟต่อไปนี้จะสามารถนำมาสร้างตัวอย่างข้อมูลได้ตามตารางด้านล่าง

<p align="center">
<img width="300" src="https://raw.githubusercontent.com/vacharapat/Adversarial-Machine-Learning/master/images/3color1.png">
</p>

| example | label | example | label |
|:-------:|:-----:|:-------:|:-----:|
|$(0,1,1,1,1,1)$|1|$(0,0,1,1,1,1)$|0|
|$(1,0,1,1,1,1)$|1|$(0,1,0,1,1,1)$|0|
|$(1,1,0,1,1,1)$|1|$(1,0,0,1,1,1)$|0|
|$(1,1,1,0,1,1)$|1|$(1,0,1,1,0,1)$|0|
|$(1,1,1,1,0,1)$|1|$(1,1,0,0,1,1)$|0|
|$(1,1,1,1,1,0)$|1|$(1,1,0,1,1,0)$|0|
|               | |$(1,1,1,0,0,1)$|0|
|               | |$(1,1,1,1,0,0)$|0|
