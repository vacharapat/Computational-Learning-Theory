{% include lib/mathjax.html %}
# VC Generalization Bound สำหรับ Consistent Hypothesis

จากหัวข้อที่แล้ว เราเห็นแล้วว่าอัตราการโตของ $\Pi_H(m)$ นั้นเป็น polynomial บน $m$
ซึ่งทำให้เรามีความหวังที่จะนำค่า $\Pi_H(m)$ มาใช้เป็นเครื่องแสดงความซับซ้อนของ hypothesis space $H$
แทนขนาดของ $H$ ได้ อย่างไรก็ดีเราไม่สามารถทำการวิเคราะห์ generalization bound ของ hypothesis
ที่ได้จากการเรียนรู้โดยใช้ union bound เช่นเดิมได้เนื่องจากขนาดของ $H$ อาจมีค่าเป็นอนันต์  ในหัวข้อนี้เราจะมาดูวิธีการวิเคราะห์ generalization bound ให้อยู่ในรูปของ $\Pi_H(m)$ แทน

## Consistent hypothesis
เราจะเริ่มพิจารณาในกรณีที่เราทราบว่ามี concept เป้าหมาย $c\in H$ อยู่จริง และเราทำการเรียนรู้โดยการหา
hypothesis $h\in H$ ที่ consistent กับตัวอย่างข้อมูลทั้งหมดที่ได้มา ซึ่งแทนด้วย $$S=\{(x_1,y_1),\dots,(x_m,y_m)\}$$

หากเราต้องการให้ hypothesis $h$ ที่ได้เป็นผลจากการเรียนรู้ของเรามี error $R(h)\leq\epsilon$
เราสามารถทำได้โดยหาขอบเขตของความน่าจะเป็นที่จะมี hypothesis อย่างน้อยตัวหนึ่งใน $H$ ที่มี error มากกว่า $\epsilon$
แต่ยังสามารถเป็นคำตอบจากอัลกอริทึมการเรียนรู้ของเราได้ นั่นคือ hypothesis ดังกล่าวต้อง consistent กับ $S$ ด้วย
เรากล่าวได้อีกอย่างว่าเป้าหมายของเราคือการหาขอบเขตของความน่าจะเป็น

$$
\Pr[\exists h\in H: R(h)>\epsilon \text{ และ } h \text{ consistent กับ } S]
$$

ในกรณีที่ $H$ มีขนาดจำกัด เราสามารถจำกัดขอบเขตของความน่าจะเป็นนี้ได้โดยหาความน่าจะเป็นที่ hypothesis
$h$ ที่ $R(h)>\epsilon$ จะ consistent กับ $S$ และใช้ union bound จำกัดขอบเขตที่จะเกิดเหตุการณ์ดังกล่าวกับ
hypothesis อย่างน้อยหนึ่งตัวได้ แต่เมื่อ $H$ มีขนาดเป็นอนันต์วิธีการนี้ก็ไม่สามารถทำได้แล้ว

## Ghost sample

เทคนิคที่เราจะใช้ในการวิเคราะห์ generalization bound เมื่อ $H$ มีขนาดเป็นอนันต์คือการลดรูป hypothesis space
$H$ ที่สนใจให้อยู่ในรูปแบบที่มีขนาดจำกัด สมมติให้ $S'$ เป็นเซตของตัวอย่างข้อมูล $m$
ตัวอีกชุดหนึ่งที่สมาชิกแต่ละตัวถูกสุ่มแบบ i.i.d. จากการกระจายตัวแบบเดียวกันกับ $S$
สำหรับ $h\in H$ ใด ๆ เราจะใช้ empirical error
$$\widehat{R}_{S'}(h)$$
เป็นตัวแทนของ $R(h)$ ในการวิเคราะห์
ซึ่งจะเห็นว่าถึงแม้ขนาดของ $H$ จะเป็นอนันต์ก็ตาม
หากเราพิจารณาผลลัพธ์ของ $h\in H$ ใด ๆ บน $S'$ ที่มีจำนวนจำกัด จำนวนของผลลัพธ์ที่เกิดขึ้นได้จะมีจำนวนจำกัดเสมอ
ซึ่งทำให้เราสามารถวิเคราะห์ขอบเขตบนของความน่าจะเป็นที่ต้องการโดยใช้ union bound เช่นเดิมได้
เราเรียก $S'$ นี้ว่า _ghost sample_ เนื่องจากเป็นตัวอย่างข้อมูลที่ไม่มีอยู่จริง
แต่เราสร้างขึ้นมาสำหรับใช้ในการวิเคราะห์เท่านั้น

ขั้นแรกเราจะแสดงความสัมพันธ์ระหว่าง $R(h)$ กับ
$$\widehat{R}_{S'}(h)$$
ก่อน โดยจะแสดงให้เห็นว่าสำหรับ $h\in H$ ที่ $R(h)>\epsilon$ เราจะได้ว่า
$$\widehat{R}_{S'}(h)>\epsilon m/2$$
ด้วยความน่าจะเป็นไม่น้อยกว่า $1/2$

สมมติให้ $r = R(h)$ เราจะได้ว่า
$$\mathbb{E}[\widehat{R}_{S'}(h)] = rm > \epsilon m$$ จาก Chebyshev's inequality ที่กล่าวว่า
สำหรับตัวแปรสุ่ม $X$ ใด ๆ

\[
\Pr[|X - \mathbb{E}[X]|\geq a]\leq \frac{Var[X]}{a^2}
\]

เราจะได้ว่า

\[
\Pr[\widehat{R}_{S'}(h)\leq\frac{\epsilon m}{2}]\leq\Pr[|\widehat{R}_{S'}(h)- rm|\geq\frac{\epsilon m}{2}]
\]
